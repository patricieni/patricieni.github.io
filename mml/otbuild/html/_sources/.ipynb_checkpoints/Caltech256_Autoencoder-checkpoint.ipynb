{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import imageio\n",
    "import matplotlib as mpl\n",
    "import itertools\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "import sys\n",
    "% matplotlib inline\n",
    "\n",
    "# Dataset & Utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Optimizer, Functions, Distributions\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch import nn \n",
    "import torch.distributions as ds\n",
    "\n",
    "\n",
    "# My models, optimizer classes - VAE, Adam\n",
    "import nldr.models\n",
    "from nldr.models import vae, Encoder, Decoder, VAE\n",
    "from nldr.models import optimizers, Optimizer\n",
    "import nldr.utils\n",
    "from nldr.utils.datasets import MNIST_Loader, Visualize, Caltech256, Caltech256_Loader\n",
    "\n",
    "# Unrelated but useful\n",
    "get_types = lambda x :[(a, getattr(x, a)) for a in dir(x) if not callable(getattr(x, a)) and a[0] != '_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found or corrupted. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6f8591367ecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m ])\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcaltech_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCaltech256\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcal_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Code/Optimal/nldr/utils/datasets/caltech.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, max_items, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             raise RuntimeError('Dataset not found or corrupted.' +\n\u001b[0;32m---> 75\u001b[0;31m                                ' You can use download=True to download it')\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found or corrupted. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "# Can always add this to the Loader class and abstract the loading aspect of it, leave here for now. \n",
    "cal_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "cal_transform1 = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(64),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "caltech_train = Caltech256(root='./data',max_items = 30, download=False, transform=cal_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(caltech_train[5][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caltech_test = Caltech256(root='./data',max_items = 40, train = False, download=False, transform=cal_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10240"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(caltech_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caltech_X_train = []\n",
    "caltech_Y_train = []\n",
    "\n",
    "caltech_X_test = []\n",
    "caltech_Y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (i,item) in enumerate(caltech_train):\n",
    "        img = item[0][0].numpy().reshape(-1)\n",
    "        caltech_X_train.append(img)\n",
    "        caltech_Y_train.append(item[1])\n",
    "for (i,item) in enumerate(caltech_test):\n",
    "        img = item[0][0].numpy().reshape(-1)\n",
    "        caltech_X_test.append(img)\n",
    "        caltech_Y_test.append(item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SIFT Descriptor? What about the channels?\n",
    "X_train = np.asarray(caltech_X_train)\n",
    "Y_train = np.asarray(caltech_Y_train)\n",
    "\n",
    "X_test = np.asarray(caltech_X_test)\n",
    "Y_test = np.asarray(caltech_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"data/caltech256_X_train\"+\".npy\",X_train)\n",
    "np.save(\"data/caltech256_Y_train\"+\".npy\",Y_train)\n",
    "\n",
    "np.save(\"data/caltech256_X_test\"+\".npy\",X_test)\n",
    "np.save(\"data/caltech256_Y_test\"+\".npy\",Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caltech_loader = Caltech256_Loader(dataset=caltech_data).load()\n",
    "cal_iter = iter(caltech_loader)\n",
    "images, labels = cal_iter.next()\n",
    "\n",
    "#classes = (0,1,2,3,4,5,6,7,8,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_image = Caltech256_Loader(dataset=caltech_data).random_image(images)\n",
    "# Should be normalized? \n",
    "plt.imshow(rand_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_loader, test_loader = MNIST_Loader(batch_size=64).load()\n",
    "train_loader, test_loader = MNIST_Loader().load(batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Why am I not able to reload specific class without restarting kernel? Is it specifically because it's a class and not a method?\n",
    "import importlib\n",
    "importlib.reload(nldr.utils)\n",
    "importlib.reload(nldr.models);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_image = MNIST_Loader().random_image(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Visualize.imshow_batch(images)\n",
    "#Visualize.display_labels(classes,labels)\n",
    "\n",
    "# Visualize a random digit from a batch\n",
    "#Visualize.imshow_random(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE Encoder/Decoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_in, H, D_out = 784, 500, 2\n",
    "encoder = Encoder(D_in, H, D_out)\n",
    "decoder = Decoder(D_out, H, D_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_vae = VAE().to(device) - if cuda is available, but not the case, yet\n",
    "model_vae = VAE(encoder,decoder)\n",
    "optimizer = Optimizer(model_vae,optimizer = optim.Adam(model_vae.parameters(), lr=1e-4),early_stopping = True)\n",
    "#optim.RMSprop(model_vae.parameters(), lr = 1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate 64 different digits. The sample is just the mean.\n",
    "# Turn on early stopping\n",
    "epochs = 30\n",
    "for epoch in range(1, epochs + 1):\n",
    "    optimizer.train_epoch(epoch,train_loader)\n",
    "    optimizer.test_epoch(epoch,test_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, D_out)\n",
    "        sample = model_vae.decode(sample)\n",
    "        save_image(sample.view(64, 1, 28, 28),\n",
    "                   'MNIST_VAE_results/sample_' + str(epoch) + '.png')\n",
    "        \n",
    "    if optimizer.early_stopping and epoch>3:\n",
    "        diff = np.abs(optimizer.average_loss[-1] - optimizer.average_loss[-3])\n",
    "        thres = diff/optimizer.average_loss[-1] * 100\n",
    "        if thres<= 0.3:\n",
    "            print(\"Performing early stopping .. \")\n",
    "            break;    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer.show_stats(show=True,save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model and Gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_vae.state_dict(), \"data/saved\" + '/VAE_Adam_1e-4_30epochs.pkl')\n",
    "# ... after training, save your model \n",
    "#model.save_state_dict('mytraining.pt')\n",
    "# .. to load your previously training model:\n",
    "#model.load_state_dict(torch.load('mytraining.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_gif = Visualize.make_gif(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model\n",
    "    * Model needs to exist first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_original = torch.load(f=\"data/saved\" + '/VAE_Adam_1e-4_30epochs.pkl')\n",
    "model_vae_original = VAE(encoder,decoder)\n",
    "model_vae_original.load_state_dict(model_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the latent space\n",
    "    * First change the number of points you plot by selecting 10000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = MNIST_Loader().load(batch_size=10000)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Feed a new batch of images and get the mean and logvar of the latent space. \n",
    "# This gives you the parameters of the Gaussian\n",
    "mu, logvar = model_vae.encode(images.view(-1, 784)) \n",
    "Visualize.plot_latent_space(mu,labels)\n",
    "# 2. Visualize the prior predictive distribution. Fix the latent variables between [-3,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the manifold\n",
    "    * Generate the 2 dimensions by encoding a digit of your choice, then perturb the reconstruction with linspace\n",
    "    * Plot the 2 latent dimensions/means in space with the associated digits they produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = np.linspace(-1, 1, 15)\n",
    "no_digit = 2\n",
    "\n",
    "img = images[no_digit]\n",
    "label = labels[no_digit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Visualize.plot_manifold(model_vae, n, img, label)\n",
    "\n",
    "# Proof it's random but not entirely, when you generate\n",
    "#Visualize.imshow_batch(res.view(-1,28,28).data)\n",
    "#Visualize.imshow_batch(res1.view(-1,28,28).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Space Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is an example that aims to further reduce the latent space. \n",
    "latent_data = LatentSpaceDataset(mu,labels)\n",
    "mini_train_loader = DataLoader(dataset=latent_data, batch_size = 100, shuffle=True)\n",
    "\n",
    "#mini_data_iter = iter(mini_train_loader)\n",
    "#datapoint, label = mini_data_iter.next()\n",
    "D_in_latent, H_latent, D_out_latent = 20, 10, 2\n",
    "encoder1 = Encoder(D_in_latent, H_latent, D_out_latent)\n",
    "decoder1 = Decoder(D_out_latent, H_latent, D_in_latent)\n",
    "\n",
    "#model_vae = VAE().to(device) - if cuda is available, but not the case, yet\n",
    "model = VAE(encoder1,decoder1)\n",
    "optimizer1 = Optimizer(model,optimizer = optim.Adam(model.parameters(), lr=1e-3))\n",
    "\n",
    "# Generate 64 different digits. The sample is just the mean.\n",
    "epochs = 15\n",
    "for epoch in range(1, epochs + 1):\n",
    "    optimizer1.train_epoch(epoch,mini_train_loader)\n",
    "    #optimizer1.test_epoch(epoch,test_loader)\n",
    "    \n",
    "mu_latent, logvar_latent = model.encode(mu.view(-1,20))    \n",
    "plot_latent_space(mu_latent,labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
