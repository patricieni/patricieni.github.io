

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Multiscale Metric Learning - GPU &mdash; Metric Learning version 58876c6</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="Metric Learning version 58876c6" href="../index.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index_ot.html" class="icon icon-home"> Metric Learning
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Multiscale Metric Learning-GPU.html">Multiscale Metric Learning - GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Multiscale Metric Learning.html">Multiscale Metric Learning</a></li>
</ul>
<p class="caption"><span class="caption-text">MML Library</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mml/mml.html">mml package</a></li>
</ul>
<p class="caption"><span class="caption-text">TODO List</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../doc/TODO.html">TODO List</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index_ot.html">Metric Learning</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index_ot.html">Docs</a> &raquo;</li>
        
      <li>Multiscale Metric Learning - GPU</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/.ipynb_checkpoints/Multiscale Metric Learning-GPU-checkpoint.ipynb" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

/* nice headers on first paragraph of info/warning boxes */
.admonition .first {
    margin: -12px;
    padding: 6px 12px;
    margin-bottom: 12px;
    color: #fff;
    line-height: 1;
    display: block;
}
.admonition.warning .first {
    background: #f0b37e;
}
.admonition.note .first {
    background: #6ab0de;
}
.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="section" id="Multiscale-Metric-Learning---GPU">
<h1>Multiscale Metric Learning - GPU<a class="headerlink" href="#Multiscale-Metric-Learning---GPU" title="Permalink to this headline">¶</a></h1>
<p>MNIST This MNIST Dataset is a collection handwritten digits. The samples
are partitioned (nearly) evenly across the 10 different digit classes
{0, 1, … , 9}. We use a preprocessed version for which the data are
8×88×8 pixel images containing one digit each. For further details on
how the digits are preprocessed, see the sklearn documentation. The
images are grayscale, with each pixel taking values in {0, 1, … ,
16}, where 0 corresponds to black (weakest intensity) and 16 corresponds
to white (strongest intensity). Therefore, the dataset is a N × 64
dimensional matrix where each dimension corresponds to a pixel from the
image and N is the number of images.</p>
<p>To replicate Cuturi we need to run the metric learning algorithm using
his approach. But that doesn’t mean we can’t run it on this 8x8 Reduced
MNIST dataset as well. Approach is to perform PCA on the reduced dataset
and then apply Cuturi’s algorithm for learning the metric. We’ll use as
an initializer the PCA reduced learned metric for the original problem
that is non PCA. 8x8 should be small enough to work. Will also implement
it using both linear programming and Sinkhorn for determining the
Wasserstein distances.</p>
<p>8x8 means 64 dimensions. You can see from the analysis done that it’s
enough to have half of them to explain 95% of variance. This is the
perfect scenario for CUTURI.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="c1"># Your code goes here</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="k">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="k">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="k">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">adjusted_rand_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="k">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="k">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">Normalizer</span>

<span class="kn">import</span> <span class="nn">metric_learn</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="k">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="k">import</span> <span class="n">NearestNeighbors</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="k">import</span> <span class="n">DistanceMetric</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors.ball_tree</span> <span class="k">import</span> <span class="n">BallTree</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="k">import</span> <span class="n">Axes3D</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">log_loss</span>

<span class="c1"># Shogun - Metric Learning</span>
<span class="kn">from</span> <span class="nn">shogun</span> <span class="k">import</span> <span class="n">LMNN</span> <span class="k">as</span> <span class="n">shogun_LMNN</span>
<span class="kn">from</span> <span class="nn">shogun</span> <span class="k">import</span> <span class="n">RealFeatures</span><span class="p">,</span> <span class="n">MulticlassLabels</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="k">import</span> <span class="n">check_X_y</span><span class="p">,</span> <span class="n">check_array</span>

<span class="c1"># POT imports</span>
<span class="kn">import</span> <span class="nn">ot</span>
<span class="kn">from</span> <span class="nn">ot.datasets</span> <span class="k">import</span> <span class="n">get_1D_gauss</span> <span class="k">as</span> <span class="n">gauss</span>

<span class="c1"># Testing</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <span class="n">testing</span>
<span class="kn">from</span> <span class="nn">timeit</span> <span class="k">import</span> <span class="n">default_timer</span> <span class="k">as</span> <span class="n">timer</span>


<span class="n">data_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()))</span> <span class="o">+</span> <span class="s2">&quot;/data/&quot;</span>
<span class="n">knn_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()))</span> <span class="o">+</span> <span class="s2">&quot;/data/knn_data/&quot;</span>
<span class="n">results_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()))</span> <span class="o">+</span> <span class="s2">&quot;/results/multiclass/&quot;</span>
<span class="n">results_lmnn</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()))</span> <span class="o">+</span> <span class="s2">&quot;/results/lmnn/&quot;</span>

<span class="k">def</span> <span class="nf">write_to_pickle</span><span class="p">(</span><span class="n">dataframe</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="n">dataframe</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">data_path</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;.pickle&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_from_pickle</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="n">data_path</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;.pickle&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">mml</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># By default train LMNN with k = 3</span>
<span class="k">def</span> <span class="nf">train_lmnn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">init_transform</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Trains an LMNN metric learning on data X_train and labels Y_train.</span>
<span class="sd">    Transforms X train and test using the learned metric.</span>
<span class="sd">    Uses init_transform as an initializer for LMNN, default np.eye(d,d)</span>
<span class="sd">    unless otherwise specified</span>

<span class="sd">    Returns: Transformed X train and test together with the learned metric, i.e.</span>
<span class="sd">    [X_train_lmnn, X_test_lmnn, lmnn.metric]</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">X_</span><span class="p">,</span> <span class="n">y_</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">Y_train</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">RealFeatures</span><span class="p">(</span><span class="n">X_</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">MulticlassLabels</span><span class="p">(</span><span class="n">y_</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">))</span>

    <span class="n">lmnn</span> <span class="o">=</span> <span class="n">shogun_LMNN</span><span class="p">(</span><span class="n">features</span><span class="p">,</span><span class="n">labels</span><span class="p">,</span><span class="n">k</span><span class="p">)</span>

    <span class="n">lmnn</span><span class="o">.</span><span class="n">set_maxiter</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span>
    <span class="n">lmnn</span><span class="o">.</span><span class="n">set_obj_threshold</span><span class="p">(</span><span class="n">threshold</span><span class="p">)</span>
    <span class="n">lmnn</span><span class="o">.</span><span class="n">set_regularization</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span>
    <span class="n">lmnn</span><span class="o">.</span><span class="n">set_stepsize</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="c1"># Below is for pullback only!!</span>
    <span class="c1">#initial_metric = pullback_metric</span>
    <span class="c1">#lmnn_shogun.train(initial_metric)</span>
    <span class="n">lmnn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">init_transform</span><span class="p">)</span>

    <span class="c1"># Metric transformation</span>
    <span class="n">lmnn_transform</span> <span class="o">=</span> <span class="n">lmnn</span><span class="o">.</span><span class="n">get_linear_transform</span><span class="p">()</span>

    <span class="c1"># Transform the input space</span>
    <span class="n">X_train_lmnn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">lmnn_transform</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">X_test_lmnn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">lmnn_transform</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">X_train_lmnn</span><span class="p">,</span> <span class="n">X_test_lmnn</span><span class="p">,</span> <span class="n">lmnn</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>Cell below not used now</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_digits</span>
<span class="n">digits</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>
<span class="c1"># Hellinger representation is sqrt of the data, try with normal representation too.</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span>
<span class="c1">#X_train,X_test,Y_train, Y_test = train_test_split(X,Y,train_size=0.8,test_size=0.2,random_state=0)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Original data normalized</span>
<span class="n">X_train_normalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">knn_path</span> <span class="o">+</span> <span class="s2">&quot;X_train_normalized.npy&quot;</span><span class="p">)</span>
<span class="n">X_test_normalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">knn_path</span> <span class="o">+</span> <span class="s2">&quot;X_test_normalized.npy&quot;</span><span class="p">)</span>
<span class="c1">#X_train_pca_normalized = np.load(knn_path + &quot;X_train_normalizedpca.npy&quot;)</span>
<span class="c1">#X_test_pca_normalized = np.load(knn_path + &quot;X_test_normalizedpca.npy&quot;)</span>

<span class="c1"># Original label data</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">knn_path</span><span class="o">+</span><span class="s2">&quot;Y_train.npy&quot;</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">knn_path</span><span class="o">+</span><span class="s2">&quot;Y_test.npy&quot;</span><span class="p">)</span>


<span class="c1"># VAE</span>
<span class="n">Y_train_vae</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">knn_path</span><span class="o">+</span><span class="s2">&quot;Y_train_vae.npy&quot;</span><span class="p">)</span>
<span class="n">Y_test_vae</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">knn_path</span><span class="o">+</span><span class="s2">&quot;Y_test_vae.npy&quot;</span><span class="p">)</span>

<span class="c1"># VAE normalized</span>
<span class="n">X_train_vae_normalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">knn_path</span> <span class="o">+</span> <span class="s2">&quot;X_train_normalized_vae.npy&quot;</span><span class="p">)</span>
<span class="n">X_test_vae_normalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">knn_path</span> <span class="o">+</span> <span class="s2">&quot;X_test_normalized_vae.npy&quot;</span><span class="p">)</span>


<span class="c1"># PCA</span>
<span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">data_path</span> <span class="o">+</span> <span class="s2">&quot;X_train_pca.npy&quot;</span><span class="p">)</span>
<span class="n">X_test_pca</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">data_path</span> <span class="o">+</span> <span class="s2">&quot;X_test_pca.npy&quot;</span><span class="p">)</span>

<span class="c1"># PCA normalized</span>
<span class="n">X_train_pca_normalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">knn_path</span> <span class="o">+</span> <span class="s2">&quot;X_train_normalized_pca_1.npy&quot;</span><span class="p">)</span>
<span class="n">X_test_pca_normalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">knn_path</span> <span class="o">+</span> <span class="s2">&quot;X_test_normalized_pca_1.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">d</span> <span class="o">=</span> <span class="n">X_train_normalized</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="c1">#x = np.arange(d,dtype=np.float64)</span>
<span class="c1">#x1 = x.reshape((d,1))</span>
<span class="c1"># By default metric =&#39;sqeuclidean&#39; in the function</span>
<span class="c1">#M_original = ot.dist(x1,x1,metric=&#39;euclidean&#39;)</span>
<span class="c1">#M_original_eye = ot.dist(x1,x1,metric=&#39;hamming&#39;)</span>

<span class="c1"># Replace first line with line below</span>
<span class="c1"># M_gml = np.load(results_path+&quot;gml_mnist_sift.npy&quot;)</span>
<span class="n">M_gml</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">results_path</span><span class="o">+</span><span class="s2">&quot;gml30samples.npy&quot;</span><span class="p">)</span>
<span class="n">M_gml_vae</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">results_path</span><span class="o">+</span><span class="s2">&quot;gml_mnist_vae.npy&quot;</span><span class="p">)</span>
<span class="n">M_gml_pca</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">results_path</span><span class="o">+</span><span class="s2">&quot;gml_mnist_sift_pca.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">M_gml_sift</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">results_path</span> <span class="o">+</span> <span class="s2">&quot;gml_mnist_sift.npy&quot;</span><span class="p">)</span>
<span class="n">M_gml_pca_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">results_path</span><span class="o">+</span><span class="s2">&quot;gml_mnist_sift_pca_1.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">M_gml_sift</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_10_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_10_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">data_path</span> <span class="o">+</span> <span class="s2">&quot;PCA_Components.npy&quot;</span><span class="p">)</span>

<span class="c1"># Use below as initializer to GML algorithm</span>
<span class="n">w2_pullback</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M_gml_pca_1</span><span class="p">,</span><span class="n">P</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">w2_pullback</span><span class="p">);</span>
<span class="n">mml</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">save_ndarray</span><span class="p">(</span><span class="n">results_path</span><span class="o">+</span><span class="s2">&quot;pullback_MNIST&quot;</span><span class="p">,</span><span class="n">w2_pullback</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_11_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_11_0.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">results_path</span><span class="o">+</span><span class="s2">&quot;pullback_MNIST.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">M</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[24]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(64, 64)
</pre></div>
</div>
</div>
<div class="section" id="LMNN-Analysis">
<h2>LMNN Analysis<a class="headerlink" href="#LMNN-Analysis" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>LMNN (Shogun ML) on the original space.</li>
<li>A lot faster than the standard LMNN due to C++ interface<ol class="arabic">
<li>Same method will be used when learning via the pullback as
initializer</li>
<li>Time it on the original space, time it on latent space, time it
with pullback initializer.</li>
<li>Run it on a grid of values for k to see how accuracies &amp; errors
change, store only the highest values</li>
</ol>
</li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">K</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">11</span><span class="p">]</span>
<span class="n">col_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;K1&#39;</span><span class="p">,</span><span class="s1">&#39;K3&#39;</span><span class="p">,</span><span class="s1">&#39;K5&#39;</span><span class="p">,</span><span class="s1">&#39;K7&#39;</span><span class="p">,</span><span class="s1">&#39;K9&#39;</span><span class="p">,</span><span class="s1">&#39;K11&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">init_transform</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="n">d</span><span class="p">)</span>
<span class="n">datasets_lmnn_train</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">datasets_lmnn_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># time it for every k</span>
<span class="n">T_default</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K</span><span class="p">:</span>
    <span class="c1"># Dataset</span>
    <span class="n">t_zero</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    <span class="n">X_train_lmnn</span><span class="p">,</span> <span class="n">X_test_lmnn</span><span class="p">,</span> <span class="n">lmnn</span>  <span class="o">=</span> <span class="n">train_lmnn</span><span class="p">(</span><span class="n">X_train_normalized</span><span class="p">,</span> <span class="n">X_test_normalized</span><span class="p">,</span><span class="n">Y_train</span><span class="p">,</span><span class="n">init_transform</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">t_after</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">t_after</span> <span class="o">-</span> <span class="n">t_zero</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time elapsed for K=</span><span class="si">%d</span><span class="s2">: </span><span class="si">%.2f</span><span class="s2"> s&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">delta</span><span class="p">))</span>
    <span class="n">T_default</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span>

    <span class="c1"># Metric transformations</span>
    <span class="n">lmnn_transform</span> <span class="o">=</span> <span class="n">lmnn</span><span class="o">.</span><span class="n">get_linear_transform</span><span class="p">()</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lmnn_transform</span><span class="p">)</span>
    <span class="n">datasets_lmnn_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_train_lmnn</span><span class="p">)</span>
    <span class="n">datasets_lmnn_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_test_lmnn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Time elapsed for K=1: 64.45 s
Time elapsed for K=3: 179.39 s
Time elapsed for K=5: 269.70 s
Time elapsed for K=7: 363.26 s
Time elapsed for K=9: 453.22 s
Time elapsed for K=11: 506.98 s
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># In case you want to store the dataframes of the LMNN transformations</span>
<span class="n">lmnn_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_lmnn</span><span class="p">)</span>
<span class="n">lmnn_test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_test_lmnn</span><span class="p">)</span>
<span class="n">write_to_pickle</span><span class="p">(</span><span class="n">lmnn_df</span><span class="p">,</span><span class="s1">&#39;mnist_lmnn_original_train&#39;</span><span class="p">)</span>
<span class="n">write_to_pickle</span><span class="p">(</span><span class="n">lmnn_test_df</span><span class="p">,</span><span class="s1">&#39;mnist_lmnn_original_test&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="1.-L_2-KNN-on-LMNN-for-6-different-datasets-(K-datasets)">
<h3>1. <span class="math notranslate nohighlight">\(L_2\)</span> KNN on LMNN for 6 different datasets (K datasets)<a class="headerlink" href="#1.-L_2-KNN-on-LMNN-for-6-different-datasets-(K-datasets)" title="Permalink to this headline">¶</a></h3>
<p>Store results in a dataframe</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df_accuracies_L2LMNN</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">col_names</span><span class="p">)</span>
<span class="n">df_accuracies_L2LMNN</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">df_errors_L2LMNN</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">col_names</span><span class="p">)</span>
<span class="n">df_errors_L2LMNN</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">datasets_lmnn_train</span><span class="p">)):</span>
    <span class="n">accuracies_lmnn</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">errors_lmnn</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K</span><span class="p">:</span>
        <span class="c1"># build a model</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">)</span>
        <span class="n">X_train_lmnn</span> <span class="o">=</span> <span class="n">datasets_lmnn_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">X_test_lmnn</span> <span class="o">=</span> <span class="n">datasets_lmnn_test</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_lmnn</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>

        <span class="c1"># evaluate and print accuracies and xEntropy Softmax error (for multiclass predictions)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_lmnn</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_lmnn</span><span class="p">)</span>
        <span class="c1">#error = getXEntropySoftmaxError(prediction, Y_test)</span>
        <span class="n">error</span><span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;K=</span><span class="si">%d</span><span class="s2">, k=</span><span class="si">%d</span><span class="s2">, accuracy=</span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">k</span><span class="p">,</span> <span class="n">score</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
        <span class="n">accuracies_lmnn</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
        <span class="n">errors_lmnn</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

    <span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">accuracies_lmnn</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;K=</span><span class="si">%d</span><span class="s2">, k=</span><span class="si">%d</span><span class="s2"> achieved highest accuracy of </span><span class="si">%.2f%%</span><span class="s2"> on test data&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">K</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
    <span class="n">accuracies_lmnn</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
    <span class="c1"># Store all results in dataframe</span>
    <span class="n">df_accuracies_L2LMNN</span><span class="p">[</span><span class="n">col_names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">accuracies_lmnn</span>
    <span class="n">df_errors_L2LMNN</span><span class="p">[</span><span class="n">col_names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">errors_lmnn</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
K=1, k=1, accuracy=93.62%
K=1, k=3, accuracy=94.14%
K=1, k=5, accuracy=93.77%
K=1, k=7, accuracy=93.40%
K=1, k=9, accuracy=93.25%
K=1, k=11, accuracy=92.88%
K=1, k=3 achieved highest accuracy of 93.62% on test data
K=3, k=1, accuracy=95.92%
K=3, k=3, accuracy=96.36%
K=3, k=5, accuracy=96.51%
K=3, k=7, accuracy=96.74%
K=3, k=9, accuracy=96.07%
K=3, k=11, accuracy=95.18%
K=3, k=7 achieved highest accuracy of 96.36% on test data
K=5, k=1, accuracy=96.74%
K=5, k=3, accuracy=97.33%
K=5, k=5, accuracy=97.11%
K=5, k=7, accuracy=96.66%
K=5, k=9, accuracy=96.44%
K=5, k=11, accuracy=96.51%
K=5, k=3 achieved highest accuracy of 97.11% on test data
K=7, k=1, accuracy=96.51%
K=7, k=3, accuracy=97.11%
K=7, k=5, accuracy=96.81%
K=7, k=7, accuracy=96.81%
K=7, k=9, accuracy=96.59%
K=7, k=11, accuracy=96.51%
K=7, k=3 achieved highest accuracy of 96.81% on test data
K=9, k=1, accuracy=96.36%
K=9, k=3, accuracy=96.81%
K=9, k=5, accuracy=96.59%
K=9, k=7, accuracy=96.59%
K=9, k=9, accuracy=96.51%
K=9, k=11, accuracy=96.07%
K=9, k=3 achieved highest accuracy of 96.51% on test data
K=11, k=1, accuracy=95.99%
K=11, k=3, accuracy=96.29%
K=11, k=5, accuracy=96.29%
K=11, k=7, accuracy=96.07%
K=11, k=9, accuracy=95.92%
K=11, k=11, accuracy=95.85%
K=11, k=3 achieved highest accuracy of 95.85% on test data
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Highest accuracy is for LMNN with 5 neighbours with KNN-3</span>
<span class="n">df_accuracies_L2LMNN</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>K1</th>
      <th>K3</th>
      <th>K5</th>
      <th>K7</th>
      <th>K9</th>
      <th>K11</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.936202</td>
      <td>0.959199</td>
      <td>0.967359</td>
      <td>0.965134</td>
      <td>0.963650</td>
      <td>0.959941</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.941395</td>
      <td>0.963650</td>
      <td>0.973294</td>
      <td>0.971068</td>
      <td>0.968101</td>
      <td>0.962908</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.937685</td>
      <td>0.965134</td>
      <td>0.971068</td>
      <td>0.968101</td>
      <td>0.965875</td>
      <td>0.962908</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.933976</td>
      <td>0.967359</td>
      <td>0.966617</td>
      <td>0.968101</td>
      <td>0.965875</td>
      <td>0.960682</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.932493</td>
      <td>0.960682</td>
      <td>0.964392</td>
      <td>0.965875</td>
      <td>0.965134</td>
      <td>0.959199</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.928783</td>
      <td>0.951780</td>
      <td>0.965134</td>
      <td>0.965134</td>
      <td>0.960682</td>
      <td>0.958457</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># When running these change names to reflect experiments</span>
<span class="n">df_accuracies_L2LMNN</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">results_lmnn</span> <span class="o">+</span> <span class="s2">&quot;L2_LMNN_Accuracies.pickle&quot;</span><span class="p">)</span>
<span class="n">df_errors_L2LMNN</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">results_lmnn</span> <span class="o">+</span> <span class="s2">&quot;L2_LMNN_Errors.pickle&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="2.-L_2-KNN-on-PCA-LMNN">
<h3>2. <span class="math notranslate nohighlight">\(L_2\)</span> KNN on PCA LMNN<a class="headerlink" href="#2.-L_2-KNN-on-PCA-LMNN" title="Permalink to this headline">¶</a></h3>
<p>Store results in dataframe</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">X_train_pca</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[13]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(449, 36)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Apply LMNN to PCA data</span>
<span class="n">lower_d</span> <span class="o">=</span> <span class="mi">36</span>
<span class="n">init_transform</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">lower_d</span><span class="p">,</span><span class="n">lower_d</span><span class="p">)</span>
<span class="n">datasets_lmnn_train_pca</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">datasets_lmnn_test_pca</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># time it for every k</span>
<span class="n">T_default_pca</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">transforms_pca</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K</span><span class="p">:</span>
    <span class="c1"># Dataset</span>
    <span class="n">t_zero</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    <span class="n">X_train_pca_lmnn</span><span class="p">,</span> <span class="n">X_test_pca_lmnn</span><span class="p">,</span> <span class="n">lmnn_pca</span> <span class="o">=</span> <span class="n">train_lmnn</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span><span class="n">X_test_pca</span><span class="p">,</span><span class="n">Y_train</span><span class="p">,</span><span class="n">init_transform</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">t_after</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">t_after</span> <span class="o">-</span> <span class="n">t_zero</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time elapsed for K=</span><span class="si">%d</span><span class="s2">: </span><span class="si">%.2f</span><span class="s2"> s&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">delta</span><span class="p">))</span>
    <span class="n">T_default_pca</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span>

    <span class="c1"># Metric transformations</span>
    <span class="n">lmnn_transform</span> <span class="o">=</span> <span class="n">lmnn_pca</span><span class="o">.</span><span class="n">get_linear_transform</span><span class="p">()</span>
    <span class="n">transforms_pca</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lmnn_transform</span><span class="p">)</span>
    <span class="n">datasets_lmnn_train_pca</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_train_pca_lmnn</span><span class="p">)</span>
    <span class="n">datasets_lmnn_test_pca</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_test_pca_lmnn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Time elapsed for K=1: 54.84 s
Time elapsed for K=3: 163.58 s
Time elapsed for K=5: 252.51 s
Time elapsed for K=7: 340.79 s
Time elapsed for K=9: 417.33 s
Time elapsed for K=11: 490.15 s
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Create dataframe to hold results</span>
<span class="n">df_accuracies_L2LMNN_PCA</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">col_names</span><span class="p">)</span>
<span class="n">df_accuracies_L2LMNN_PCA</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">df_errors_L2LMNN_PCA</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">col_names</span><span class="p">)</span>
<span class="n">df_errors_L2LMNN_PCA</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Train KNN for all datasets for K different values</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">datasets_lmnn_train_pca</span><span class="p">)):</span>
    <span class="n">accuracies_lmnn</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">errors_lmnn</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K</span><span class="p">:</span>
        <span class="c1"># build a model</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">)</span>
        <span class="n">X_train_lmnn</span> <span class="o">=</span> <span class="n">datasets_lmnn_train_pca</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">X_test_lmnn</span> <span class="o">=</span> <span class="n">datasets_lmnn_test_pca</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_lmnn</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>

        <span class="c1"># evaluate and print accuracies and xEntropy Softmax error (for multiclass predictions)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_lmnn</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_lmnn</span><span class="p">)</span>
        <span class="c1">#error = getXEntropySoftmaxError(prediction, Y_test)</span>
        <span class="n">error</span><span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;K=</span><span class="si">%d</span><span class="s2">, k=</span><span class="si">%d</span><span class="s2">, accuracy=</span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">k</span><span class="p">,</span> <span class="n">score</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
        <span class="n">accuracies_lmnn</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
        <span class="n">errors_lmnn</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

    <span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">accuracies_lmnn</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;K=</span><span class="si">%d</span><span class="s2">, k=</span><span class="si">%d</span><span class="s2"> achieved highest accuracy of </span><span class="si">%.2f%%</span><span class="s2"> on test data&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">K</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
    <span class="n">accuracies_lmnn</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
    <span class="c1"># Store all results in dataframe</span>
    <span class="n">df_accuracies_L2LMNN_PCA</span><span class="p">[</span><span class="n">col_names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">accuracies_lmnn</span>
    <span class="n">df_errors_L2LMNN_PCA</span><span class="p">[</span><span class="n">col_names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">errors_lmnn</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
K=1, k=1, accuracy=93.47%
K=1, k=3, accuracy=94.58%
K=1, k=5, accuracy=93.47%
K=1, k=7, accuracy=93.84%
K=1, k=9, accuracy=93.32%
K=1, k=11, accuracy=93.10%
K=1, k=3 achieved highest accuracy of 93.47% on test data
K=3, k=1, accuracy=95.92%
K=3, k=3, accuracy=96.36%
K=3, k=5, accuracy=96.51%
K=3, k=7, accuracy=96.36%
K=3, k=9, accuracy=95.85%
K=3, k=11, accuracy=95.25%
K=3, k=5 achieved highest accuracy of 96.36% on test data
K=5, k=1, accuracy=96.36%
K=5, k=3, accuracy=97.11%
K=5, k=5, accuracy=97.26%
K=5, k=7, accuracy=96.66%
K=5, k=9, accuracy=96.66%
K=5, k=11, accuracy=96.44%
K=5, k=5 achieved highest accuracy of 97.26% on test data
K=7, k=1, accuracy=96.51%
K=7, k=3, accuracy=97.03%
K=7, k=5, accuracy=96.88%
K=7, k=7, accuracy=96.88%
K=7, k=9, accuracy=96.59%
K=7, k=11, accuracy=96.59%
K=7, k=3 achieved highest accuracy of 96.88% on test data
K=9, k=1, accuracy=96.66%
K=9, k=3, accuracy=96.66%
K=9, k=5, accuracy=96.74%
K=9, k=7, accuracy=96.96%
K=9, k=9, accuracy=96.81%
K=9, k=11, accuracy=96.29%
K=9, k=7 achieved highest accuracy of 96.81% on test data
K=11, k=1, accuracy=96.74%
K=11, k=3, accuracy=96.81%
K=11, k=5, accuracy=97.03%
K=11, k=7, accuracy=96.81%
K=11, k=9, accuracy=96.66%
K=11, k=11, accuracy=96.44%
K=11, k=5 achieved highest accuracy of 96.44% on test data
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df_accuracies_L2LMNN_PCA</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[16]:
</pre></div>
</div>
<div class="output_area docutils container">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>K1</th>
      <th>K3</th>
      <th>K5</th>
      <th>K7</th>
      <th>K9</th>
      <th>K11</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.934718</td>
      <td>0.959199</td>
      <td>0.963650</td>
      <td>0.965134</td>
      <td>0.966617</td>
      <td>0.967359</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.945846</td>
      <td>0.963650</td>
      <td>0.971068</td>
      <td>0.970326</td>
      <td>0.966617</td>
      <td>0.968101</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.934718</td>
      <td>0.965134</td>
      <td>0.972552</td>
      <td>0.968843</td>
      <td>0.967359</td>
      <td>0.970326</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.938427</td>
      <td>0.963650</td>
      <td>0.966617</td>
      <td>0.968843</td>
      <td>0.969585</td>
      <td>0.968101</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.933234</td>
      <td>0.958457</td>
      <td>0.966617</td>
      <td>0.965875</td>
      <td>0.968101</td>
      <td>0.966617</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.931009</td>
      <td>0.952522</td>
      <td>0.964392</td>
      <td>0.965875</td>
      <td>0.962908</td>
      <td>0.964392</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Run only if you are changing experiments somehow</span>
<span class="n">df_accuracies_L2LMNN_PCA</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">results_lmnn</span> <span class="o">+</span> <span class="s2">&quot;L2_LMNN_Accuracies_PCA.pickle&quot;</span><span class="p">)</span>
<span class="n">df_errors_L2LMNN_PCA</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">results_lmnn</span> <span class="o">+</span> <span class="s2">&quot;L2_LMNN_Errors_PCA.pickle&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pl</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-darkgrid&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">17</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_accuracies_L2LMNN</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">color</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">df_accuracies_L2LMNN</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;kNN Accuracies for K-trained LMNN&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;K values&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracies&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_accuracies_L2LMNN_PCA</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">color</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">df_accuracies_L2LMNN_PCA</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;kNN Accuracies for PCA K-trained LMNN&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;K values&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">results_lmnn</span> <span class="o">+</span> <span class="s2">&quot;L2_LMNN_Accuracies.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_29_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_29_0.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df_T_default</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">T_default</span><span class="p">)</span>
<span class="n">df_T_default_pca</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">T_default_pca</span><span class="p">)</span>

<span class="n">df_T_default</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">results_lmnn</span> <span class="o">+</span> <span class="s2">&quot;L2_LMNN_Train_time.pickle&quot;</span><span class="p">)</span>
<span class="n">df_T_default_pca</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">results_lmnn</span> <span class="o">+</span> <span class="s2">&quot;L2_LMNN_PCA_Train_time.pickle&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df_T_default</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[19]:
</pre></div>
</div>
<div class="output_area docutils container">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>64.453080</td>
    </tr>
    <tr>
      <th>1</th>
      <td>179.390063</td>
    </tr>
    <tr>
      <th>2</th>
      <td>269.703305</td>
    </tr>
    <tr>
      <th>3</th>
      <td>363.259518</td>
    </tr>
    <tr>
      <th>4</th>
      <td>453.220329</td>
    </tr>
    <tr>
      <th>5</th>
      <td>506.977149</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
<div class="section" id="3.-L_2-KNN-on-Pullback-LMNN-PCA">
<h3>3. <span class="math notranslate nohighlight">\(L_2\)</span> KNN on Pullback LMNN PCA<a class="headerlink" href="#3.-L_2-KNN-on-Pullback-LMNN-PCA" title="Permalink to this headline">¶</a></h3>
<p>Pullback of PCA metric through the inverse transformation to reach the
dimension of the upper metric</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">lmnn_pullbacks</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">lmnn_pullback_metrics</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">linear_transform</span> <span class="ow">in</span> <span class="n">transforms_pca</span><span class="p">:</span>
    <span class="n">L_pca</span> <span class="o">=</span> <span class="n">linear_transform</span>
    <span class="n">pullback</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_pca</span><span class="p">,</span><span class="n">P</span><span class="p">))</span>
    <span class="n">lmnn_pullbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pullback</span><span class="p">)</span>

    <span class="n">M_pca</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_pca</span><span class="p">,</span><span class="n">L_pca</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">pullback_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M_pca</span><span class="p">,</span><span class="n">P</span><span class="p">))</span>
    <span class="n">lmnn_pullback_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pullback_1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Visualize first pullback as an example</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">lmnn_pullbacks</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">lmnn_pullback_metrics</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_35_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_35_0.png" />
</div>
</div>
<ol class="lowerroman simple">
<li>first formula <span class="math notranslate nohighlight">\(P * L * P^T\)</span></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Train LMNN using pullbacks as initializers and time it</span>
<span class="c1"># Compare not only accuracies but time it took to train LMNN whilst initializing with pullback</span>
<span class="c1"># Below will give you times.</span>
<span class="n">datasets_lmnn_train_pullback_pca</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">datasets_lmnn_test_pullback_pca</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># time it for every k</span>
<span class="n">T_default_pullback_pca</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">transforms_pullback_pca</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
    <span class="c1"># Dataset</span>
    <span class="n">t_zero</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    <span class="n">X_train_lmnn</span><span class="p">,</span> <span class="n">X_test_lmnn</span><span class="p">,</span> <span class="n">lmnn</span>  <span class="o">=</span> <span class="n">train_lmnn</span><span class="p">(</span><span class="n">X_train_normalized</span><span class="p">,</span> <span class="n">X_test_normalized</span><span class="p">,</span><span class="n">Y_train</span><span class="p">,</span><span class="n">lmnn_pullbacks</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">t_after</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">t_after</span> <span class="o">-</span> <span class="n">t_zero</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time elapsed for K=</span><span class="si">%d</span><span class="s2">: </span><span class="si">%.2f</span><span class="s2"> s&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">delta</span><span class="p">))</span>
    <span class="n">T_default_pullback_pca</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span>

    <span class="c1"># Metric transformations</span>
    <span class="n">lmnn_transform</span> <span class="o">=</span> <span class="n">lmnn</span><span class="o">.</span><span class="n">get_linear_transform</span><span class="p">()</span>
    <span class="n">transforms_pullback_pca</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lmnn_transform</span><span class="p">)</span>
    <span class="n">datasets_lmnn_train_pullback_pca</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_train_lmnn</span><span class="p">)</span>
    <span class="n">datasets_lmnn_test_pullback_pca</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_test_lmnn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Time elapsed for K=1: 1.92 s
Time elapsed for K=3: 0.11 s
Time elapsed for K=5: 0.17 s
Time elapsed for K=7: 0.23 s
Time elapsed for K=9: 16.13 s
Time elapsed for K=11: 20.87 s
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df_accuracies_L2LMNN_pullback</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">col_names</span><span class="p">)</span>
<span class="n">df_accuracies_L2LMNN_pullback</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">df_errors_L2LMNN_pullback</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">col_names</span><span class="p">)</span>
<span class="n">df_errors_L2LMNN_pullback</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">datasets_lmnn_train_pullback_pca</span><span class="p">)):</span>
    <span class="n">accuracies_lmnn</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">errors_lmnn</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K</span><span class="p">:</span>
        <span class="c1"># build a model</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">)</span>
        <span class="n">X_train_lmnn</span> <span class="o">=</span> <span class="n">datasets_lmnn_train_pullback_pca</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">X_test_lmnn</span> <span class="o">=</span> <span class="n">datasets_lmnn_test_pullback_pca</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_lmnn</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>

        <span class="c1"># evaluate and print accuracies and xEntropy Softmax error (for multiclass predictions)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_lmnn</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_lmnn</span><span class="p">)</span>
        <span class="c1">#error = getXEntropySoftmaxError(prediction, Y_test)</span>
        <span class="n">error</span><span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;K=</span><span class="si">%d</span><span class="s2">, k=</span><span class="si">%d</span><span class="s2">, accuracy=</span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">k</span><span class="p">,</span> <span class="n">score</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
        <span class="n">accuracies_lmnn</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
        <span class="n">errors_lmnn</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

    <span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">accuracies_lmnn</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;K=</span><span class="si">%d</span><span class="s2">, k=</span><span class="si">%d</span><span class="s2"> achieved highest accuracy of </span><span class="si">%.2f%%</span><span class="s2"> on test data&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">K</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
    <span class="n">accuracies_lmnn</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
    <span class="c1"># Store all results in dataframe</span>
    <span class="n">df_accuracies_L2LMNN_pullback</span><span class="p">[</span><span class="n">col_names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">accuracies_lmnn</span>
    <span class="n">df_errors_L2LMNN_pullback</span><span class="p">[</span><span class="n">col_names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">errors_lmnn</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
K=1, k=1, accuracy=93.47%
K=1, k=3, accuracy=94.58%
K=1, k=5, accuracy=93.47%
K=1, k=7, accuracy=93.84%
K=1, k=9, accuracy=93.32%
K=1, k=11, accuracy=93.10%
K=1, k=3 achieved highest accuracy of 93.47% on test data
K=3, k=1, accuracy=95.92%
K=3, k=3, accuracy=96.36%
K=3, k=5, accuracy=96.51%
K=3, k=7, accuracy=96.36%
K=3, k=9, accuracy=95.85%
K=3, k=11, accuracy=95.25%
K=3, k=5 achieved highest accuracy of 96.36% on test data
K=5, k=1, accuracy=96.36%
K=5, k=3, accuracy=97.11%
K=5, k=5, accuracy=97.26%
K=5, k=7, accuracy=96.66%
K=5, k=9, accuracy=96.66%
K=5, k=11, accuracy=96.44%
K=5, k=5 achieved highest accuracy of 97.26% on test data
K=7, k=1, accuracy=96.51%
K=7, k=3, accuracy=97.03%
K=7, k=5, accuracy=96.88%
K=7, k=7, accuracy=96.88%
K=7, k=9, accuracy=96.59%
K=7, k=11, accuracy=96.59%
K=7, k=3 achieved highest accuracy of 96.88% on test data
K=9, k=1, accuracy=96.59%
K=9, k=3, accuracy=96.88%
K=9, k=5, accuracy=96.88%
K=9, k=7, accuracy=96.59%
K=9, k=9, accuracy=96.51%
K=9, k=11, accuracy=96.07%
K=9, k=3 achieved highest accuracy of 96.51% on test data
K=11, k=1, accuracy=96.22%
K=11, k=3, accuracy=96.96%
K=11, k=5, accuracy=96.51%
K=11, k=7, accuracy=96.36%
K=11, k=9, accuracy=96.36%
K=11, k=11, accuracy=95.99%
K=11, k=3 achieved highest accuracy of 95.99% on test data
</pre></div></div>
</div>
<ol class="lowerroman simple" start="2">
<li>second formula <span class="math notranslate nohighlight">\(P * L*L^T * P^T\)</span></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Train LMNN using pullbacks as initializers and time it</span>
<span class="c1"># Compare not only accuracies but time it took to train LMNN whilst initializing with pullback</span>
<span class="c1"># Below will give you times.</span>
<span class="n">datasets_lmnn_train_pullback_metrics_pca</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">datasets_lmnn_test_pullback_metrics_pca</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># time it for every k</span>
<span class="n">T_default_pullback_pca</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">transforms_pullback_pca</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
    <span class="c1"># Dataset</span>
    <span class="n">t_zero</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    <span class="n">X_train_lmnn</span><span class="p">,</span> <span class="n">X_test_lmnn</span><span class="p">,</span> <span class="n">lmnn</span>  <span class="o">=</span> <span class="n">train_lmnn</span><span class="p">(</span><span class="n">X_train_normalized</span><span class="p">,</span> <span class="n">X_test_normalized</span><span class="p">,</span><span class="n">Y_train</span><span class="p">,</span><span class="n">lmnn_pullback_metrics</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">t_after</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">t_after</span> <span class="o">-</span> <span class="n">t_zero</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time elapsed for K=</span><span class="si">%d</span><span class="s2">: </span><span class="si">%.2f</span><span class="s2"> s&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">delta</span><span class="p">))</span>
    <span class="n">T_default_pullback_pca</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span>

    <span class="c1"># Metric transformations</span>
    <span class="n">lmnn_transform</span> <span class="o">=</span> <span class="n">lmnn</span><span class="o">.</span><span class="n">get_linear_transform</span><span class="p">()</span>
    <span class="n">transforms_pullback_pca</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lmnn_transform</span><span class="p">)</span>
    <span class="n">datasets_lmnn_train_pullback_metrics_pca</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_train_lmnn</span><span class="p">)</span>
    <span class="n">datasets_lmnn_test_pullback_metrics_pca</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_test_lmnn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Time elapsed for K=1: 2.70 s
Time elapsed for K=3: 5.80 s
Time elapsed for K=5: 8.09 s
Time elapsed for K=7: 10.74 s
Time elapsed for K=9: 14.29 s
Time elapsed for K=11: 19.31 s
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df_accuracies_L2LMNN_pullback_metrics</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">col_names</span><span class="p">)</span>
<span class="n">df_accuracies_L2LMNN_pullback_metrics</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">df_errors_L2LMNN_pullback_metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">col_names</span><span class="p">)</span>
<span class="n">df_errors_L2LMNN_pullback_metrics</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">datasets_lmnn_train_pullback_pca</span><span class="p">)):</span>
    <span class="n">accuracies_lmnn</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">errors_lmnn</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K</span><span class="p">:</span>
        <span class="c1"># build a model</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">)</span>
        <span class="n">X_train_lmnn</span> <span class="o">=</span> <span class="n">datasets_lmnn_train_pullback_metrics_pca</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">X_test_lmnn</span> <span class="o">=</span> <span class="n">datasets_lmnn_test_pullback_metrics_pca</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_lmnn</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>

        <span class="c1"># evaluate and print accuracies and xEntropy Softmax error (for multiclass predictions)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_lmnn</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_lmnn</span><span class="p">)</span>
        <span class="c1">#error = getXEntropySoftmaxError(prediction, Y_test)</span>
        <span class="n">error</span><span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;K=</span><span class="si">%d</span><span class="s2">, k=</span><span class="si">%d</span><span class="s2">, accuracy=</span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">k</span><span class="p">,</span> <span class="n">score</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
        <span class="n">accuracies_lmnn</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
        <span class="n">errors_lmnn</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

    <span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">accuracies_lmnn</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;K=</span><span class="si">%d</span><span class="s2">, k=</span><span class="si">%d</span><span class="s2"> achieved highest accuracy of </span><span class="si">%.2f%%</span><span class="s2"> on test data&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">K</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
    <span class="n">accuracies_lmnn</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
    <span class="c1"># Store all results in dataframe</span>
    <span class="n">df_accuracies_L2LMNN_pullback_metrics</span><span class="p">[</span><span class="n">col_names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">accuracies_lmnn</span>
    <span class="n">df_errors_L2LMNN_pullback_metrics</span><span class="p">[</span><span class="n">col_names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">errors_lmnn</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
K=1, k=1, accuracy=92.06%
K=1, k=3, accuracy=92.51%
K=1, k=5, accuracy=91.77%
K=1, k=7, accuracy=91.39%
K=1, k=9, accuracy=90.80%
K=1, k=11, accuracy=89.76%
K=1, k=3 achieved highest accuracy of 92.06% on test data
K=3, k=1, accuracy=95.85%
K=3, k=3, accuracy=96.29%
K=3, k=5, accuracy=96.07%
K=3, k=7, accuracy=95.99%
K=3, k=9, accuracy=94.88%
K=3, k=11, accuracy=94.14%
K=3, k=3 achieved highest accuracy of 96.29% on test data
K=5, k=1, accuracy=95.99%
K=5, k=3, accuracy=96.44%
K=5, k=5, accuracy=96.44%
K=5, k=7, accuracy=96.44%
K=5, k=9, accuracy=96.07%
K=5, k=11, accuracy=95.62%
K=5, k=3 achieved highest accuracy of 96.44% on test data
K=7, k=1, accuracy=95.99%
K=7, k=3, accuracy=96.51%
K=7, k=5, accuracy=96.59%
K=7, k=7, accuracy=96.36%
K=7, k=9, accuracy=96.59%
K=7, k=11, accuracy=96.44%
K=7, k=5 achieved highest accuracy of 96.36% on test data
K=9, k=1, accuracy=95.70%
K=9, k=3, accuracy=95.85%
K=9, k=5, accuracy=95.62%
K=9, k=7, accuracy=95.77%
K=9, k=9, accuracy=95.92%
K=9, k=11, accuracy=95.55%
K=9, k=9 achieved highest accuracy of 95.92% on test data
K=11, k=1, accuracy=95.25%
K=11, k=3, accuracy=95.55%
K=11, k=5, accuracy=95.70%
K=11, k=7, accuracy=95.33%
K=11, k=9, accuracy=95.55%
K=11, k=11, accuracy=95.33%
K=11, k=5 achieved highest accuracy of 95.33% on test data
</pre></div></div>
</div>
<p>____!Look at the times!!!____</p>
</div>
<div class="section" id="Plot-the-pullback-vs-original-accuracies">
<h3>Plot the pullback vs original accuracies<a class="headerlink" href="#Plot-the-pullback-vs-original-accuracies" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pl</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-darkgrid&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">17</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_accuracies_L2LMNN</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">color</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">df_accuracies_L2LMNN</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;kNN Accuracies for K-trained LMNN&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;K values&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracies&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_accuracies_L2LMNN_pullback</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">color</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">df_accuracies_L2LMNN_pullback</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;kNN Accuracies for pullback K-trained LMNN&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;K values&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">results_lmnn</span> <span class="o">+</span> <span class="s2">&quot;L2_LMNN_Pullback_Accuracies.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_44_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_44_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># A bit of visuals</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>

<span class="c1"># Original image</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;gray_r&#39;</span><span class="p">,</span><span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;0.1f&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">5</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Normally scaled (sqrt) image&#39;</span><span class="p">)</span>

<span class="c1"># LMNN image</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">datasets_lmnn_train</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;0.1f&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;LMNN&#39;</span><span class="p">)</span>

<span class="c1"># Normalized</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X_train_normalized</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;0.1f&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original (sqrt) normalized&#39;</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_45_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_45_0.png" />
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Wasserstein-Analysis">
<h2>Wasserstein Analysis<a class="headerlink" href="#Wasserstein-Analysis" title="Permalink to this headline">¶</a></h2>
<p>As opposed to LMNN we’ll do the analysis with only one ground metric
that was learned with k=3. GML is Ground Metric Learning.</p>
<p>We’re running the analysis only with K1 = [1,3,5] until I get
Wasserstein to run faster or use Sinkhorn</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">K1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="4.-W_2-KNN-with-GML">
<h3>4. <span class="math notranslate nohighlight">\(W_2\)</span> KNN with GML<a class="headerlink" href="#4.-W_2-KNN-with-GML" title="Permalink to this headline">¶</a></h3>
<p>Equivalent to what Cuturi did</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [40]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Transform into histogram since LMNN is non-normalized</span>
<span class="c1"># Wasserstein needs normalized data</span>
<span class="c1">#[X_train_normalized, X_test_normalized] = mml.transform.normalize(X_train,X_test,&#39;l1&#39;)</span>

<span class="c1"># K Nearest Neighbour with predefined metric</span>
<span class="c1"># model_wasserstein = KNeighborsClassifier(n_neighbors=k,metric=&#39;pyfunc&#39;)</span>
<span class="n">acc_wasserstein_l2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">errors_wasserstein_l2</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K1</span><span class="p">:</span>
    <span class="n">model_l2_wasserstein</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="n">mml</span><span class="o">.</span><span class="n">wasserstein</span><span class="o">.</span><span class="n">distance</span><span class="p">,</span>\
                                                  <span class="n">metric_params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;ground metric&quot;</span><span class="p">:</span><span class="n">M_gml_sift</span><span class="p">})</span>
    <span class="n">model_l2_wasserstein</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_normalized</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>

    <span class="n">score_w</span> <span class="o">=</span> <span class="n">model_l2_wasserstein</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_normalized</span><span class="p">,</span><span class="n">Y_test</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model_l2_wasserstein</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_normalized</span><span class="p">)</span>

    <span class="n">error</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2">, accuracy=</span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">score_w</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
    <span class="n">acc_wasserstein_l2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score_w</span><span class="p">)</span>
    <span class="n">errors_wasserstein_l2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>


<span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">acc_wasserstein_l2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2"> achieved highest accuracy of </span><span class="si">%.2f%%</span><span class="s2"> on test data&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">K1</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
<span class="n">acc_wasserstein_l2</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
k=1, accuracy=96.81%
k=3, accuracy=96.29%
k=5, accuracy=96.44%
k=1 achieved highest accuracy of 96.81% on test data
</pre></div></div>
</div>
</div>
<div class="section" id="5.-W_2-KNN-with-PCA-GML">
<h3>5. <span class="math notranslate nohighlight">\(W_2\)</span> KNN with PCA GML<a class="headerlink" href="#5.-W_2-KNN-with-PCA-GML" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [41]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Add the maximum minimum value to each sample. Then normalize to histograms</span>
<span class="c1">#[X_train_pca_normalized,X_test_pca_normalized] = mml.transform.positive_and_normalize(X_train_pca,X_test_pca,&#39;l1&#39;)</span>

<span class="n">acc_knn_pca_wasserstein</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">errors_knn_pca_wasserstein</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#d_pca = X_train_pca_normalized.shape[1]</span>
<span class="c1">#x_pca = np.arange(d_pca,dtype=np.float64)</span>
<span class="c1">#x1_pca = x_pca.reshape((d_pca,1))</span>
<span class="c1"># By default metric =&#39;sqeuclidean&#39; in the function</span>
<span class="c1">#ground_pca = ot.dist(x1_pca,x1_pca,metric=&#39;euclidean&#39;)</span>


<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K1</span><span class="p">:</span>
    <span class="n">pca_model_wasserstein</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="n">mml</span><span class="o">.</span><span class="n">wasserstein</span><span class="o">.</span><span class="n">distance</span><span class="p">,</span>\
                                                 <span class="n">metric_params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;ground metric&quot;</span><span class="p">:</span><span class="n">M_gml_pca_1</span><span class="p">})</span>
    <span class="n">pca_model_wasserstein</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca_normalized</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>

    <span class="n">score_w</span> <span class="o">=</span> <span class="n">pca_model_wasserstein</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_pca_normalized</span><span class="p">,</span><span class="n">Y_test</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">pca_model_wasserstein</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_pca_normalized</span><span class="p">)</span>

    <span class="n">error</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2">, accuracy=</span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">score_w</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>

    <span class="n">acc_knn_pca_wasserstein</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score_w</span><span class="p">)</span>
    <span class="n">errors_knn_pca_wasserstein</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

<span class="c1"># find the value of k that has the largest accuracy</span>
<span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">acc_knn_pca_wasserstein</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2"> achieved highest accuracy of </span><span class="si">%.2f%%</span><span class="s2"> on test data&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">K1</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
<span class="n">acc_knn_pca_wasserstein</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
k=1, accuracy=92.95%
k=3, accuracy=92.66%
k=5, accuracy=92.43%
k=1 achieved highest accuracy of 92.95% on test data
</pre></div></div>
</div>
</div>
<div class="section" id="6.-W_2-KNN-Pullback">
<h3>6. <span class="math notranslate nohighlight">\(W_2\)</span> KNN Pullback<a class="headerlink" href="#6.-W_2-KNN-Pullback" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">a</span><span class="p">)</span> <span class="n">PCA</span> <span class="n">Pullback</span> <span class="n">acts</span> <span class="k">as</span> <span class="n">GML</span> <span class="n">on</span> <span class="n">original</span> <span class="n">space</span>
<span class="n">b</span><span class="p">)</span> <span class="n">PCA</span> <span class="n">Pullback</span> <span class="n">used</span> <span class="k">as</span> <span class="n">initializer</span> <span class="n">to</span> <span class="n">learn</span> <span class="n">GML</span> <span class="n">faster</span> <span class="n">on</span> <span class="n">original</span> <span class="n">space</span>
</pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># P are PCA components</span>
<span class="c1"># Will use w2_pullback as part of the algorithm</span>
<span class="n">w2_pullback</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M_gml_pca_1</span><span class="p">,</span><span class="n">P</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">w2_pullback</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_54_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_54_0.png" />
</div>
</div>
<ol class="loweralpha simple">
<li>We pullback GML on PCA to GML on original space and look at KNN
accuracy and error</li>
</ol>
<p>** Horrible accuracy - but then again, why would the pullback be a
good indicator of the true GML**</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">X_train_normalized</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[26]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(449, 64)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">X_test_normalized</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[27]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(1348, 64)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Transform into histogram since LMNN is non-normalized</span>
<span class="c1"># Wasserstein needs normalized data</span>
<span class="c1">#[X_train_normalized, X_test_normalized] = mml.transform.normalize(X_train,X_test,&#39;l1&#39;)</span>

<span class="c1"># K Nearest Neighbour with predefined metric</span>
<span class="c1"># model_wasserstein = KNeighborsClassifier(n_neighbors=k,metric=&#39;pyfunc&#39;)</span>
<span class="n">acc_wasserstein_pullback</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">errors_wasserstein_pullback</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K1</span><span class="p">:</span>
    <span class="n">model_l2_wasserstein</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="n">mml</span><span class="o">.</span><span class="n">wasserstein</span><span class="o">.</span><span class="n">distance</span><span class="p">,</span>\
                                                  <span class="n">metric_params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;ground metric&quot;</span><span class="p">:</span><span class="n">w2_pullback</span><span class="p">})</span>
    <span class="n">model_l2_wasserstein</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_normalized</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>

    <span class="n">score_w</span> <span class="o">=</span> <span class="n">model_l2_wasserstein</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_normalized</span><span class="p">,</span><span class="n">Y_test</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model_l2_wasserstein</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_normalized</span><span class="p">)</span>

    <span class="n">error</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2">, accuracy=</span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">score_w</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
    <span class="n">acc_wasserstein_pullback</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score_w</span><span class="p">)</span>
    <span class="n">errors_wasserstein_pullback</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>


<span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">acc_wasserstein_pullback</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2"> achieved highest accuracy of </span><span class="si">%.2f%%</span><span class="s2"> on test data&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">K1</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
<span class="n">acc_wasserstein_pullback</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
k=1, accuracy=20.10%
k=3, accuracy=22.03%
k=5, accuracy=19.58%
k=3 achieved highest accuracy of 22.03% on test data
</pre></div></div>
</div>
<ol class="loweralpha" start="2">
<li><p class="first">We pullback GML on PCA to original space and initialize learning GML
with pullback. Repeat step 4 afterwards to find and compare KNN
accuracy and error as well as time taken to learn.</p>
<p>All experiments related to learning GML run on buck.inf.ed.ac.uk
which has a Titan X (but regular Wasserstein doesn’t work on Titan X)</p>
</li>
</ol>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">gml_pullback</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">results_path</span> <span class="o">+</span> <span class="s2">&quot;gml_mnist_sift_pullback.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">gml_pullback_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">results_path</span> <span class="o">+</span> <span class="s2">&quot;gml_mnist_sift_pullback_1.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>They do look very similar and one took half the time to train. I need a
much more grounded way of stopping the training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">gml_pullback_1</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_63_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_63_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">gml_pullback</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_64_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_64_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Check what the difference is between them</span>
<span class="n">diff</span> <span class="o">=</span> <span class="n">gml_pullback</span> <span class="o">-</span> <span class="n">gml_pullback_1</span>
<span class="n">diff</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[15]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>1.1364800000000002
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Transform into histogram since LMNN is non-normalized</span>
<span class="c1"># Wasserstein needs normalized data</span>
<span class="c1">#[X_train_normalized, X_test_normalized] = mml.transform.normalize(X_train,X_test,&#39;l1&#39;)</span>

<span class="c1"># K Nearest Neighbour with predefined metric</span>
<span class="c1"># model_wasserstein = KNeighborsClassifier(n_neighbors=k,metric=&#39;pyfunc&#39;)</span>
<span class="n">acc_wasserstein_pullback</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">errors_wasserstein_pullback</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K1</span><span class="p">:</span>
    <span class="n">model_l2_wasserstein</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="n">mml</span><span class="o">.</span><span class="n">wasserstein</span><span class="o">.</span><span class="n">distance</span><span class="p">,</span>\
                                                  <span class="n">metric_params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;ground metric&quot;</span><span class="p">:</span><span class="n">gml_pullback_1</span><span class="p">})</span>
    <span class="n">model_l2_wasserstein</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_normalized</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>

    <span class="n">score_w</span> <span class="o">=</span> <span class="n">model_l2_wasserstein</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_normalized</span><span class="p">,</span><span class="n">Y_test</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model_l2_wasserstein</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_normalized</span><span class="p">)</span>

    <span class="n">error</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2">, accuracy=</span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">score_w</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
    <span class="n">acc_wasserstein_pullback</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score_w</span><span class="p">)</span>
    <span class="n">errors_wasserstein_pullback</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>


<span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">acc_wasserstein_pullback</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2"> achieved highest accuracy of </span><span class="si">%.2f%%</span><span class="s2"> on test data&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">K1</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
<span class="n">acc_wasserstein_pullback</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
k=1, accuracy=96.44%
k=3, accuracy=95.92%
k=5, accuracy=96.22%
k=1 achieved highest accuracy of 96.44% on test data
</pre></div></div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Ignore-below-here:">
<h2>Ignore below here:<a class="headerlink" href="#Ignore-below-here:" title="Permalink to this headline">¶</a></h2>
<p>VAE Space - this will go into each analysis separately.</p>
<div class="section" id="7.-L2-KNN-with-VAE-LMNN">
<h3>7. L2 KNN with VAE LMNN<a class="headerlink" href="#7.-L2-KNN-with-VAE-LMNN" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [49]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Apply LMNN to PCA data</span>
<span class="n">init_vae</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span><span class="mi">25</span><span class="p">)</span>
<span class="p">[</span><span class="n">X_train_vae_lmnn</span><span class="p">,</span> <span class="n">X_test_vae_lmnn</span><span class="p">,</span> <span class="n">lmnn_vae</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_lmnn</span><span class="p">(</span><span class="n">X_train_vae_normalized</span><span class="p">,</span><span class="n">X_test_vae_normalized</span><span class="p">,</span><span class="n">Y_train_vae</span><span class="p">,</span><span class="n">init_vae</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [50]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">accuracies_vae_lmnn</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">errors_vae_lmnn</span> <span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K</span><span class="p">:</span>
    <span class="c1"># build a model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_vae_lmnn</span><span class="p">,</span><span class="n">Y_train_vae</span><span class="p">)</span>

    <span class="c1"># evaluate and print accuracies and xEntropy Softmax error (for multiclass predictions)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_vae_lmnn</span><span class="p">,</span> <span class="n">Y_test_vae</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_vae_lmnn</span><span class="p">)</span>
    <span class="c1">#error = getXEntropySoftmaxError(prediction, Y_test)</span>
    <span class="n">error</span><span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">Y_test_vae</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2">, accuracy=</span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">score</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
    <span class="n">accuracies_vae_lmnn</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="n">errors_vae_lmnn</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

<span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">accuracies_vae_lmnn</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2"> achieved highest accuracy of </span><span class="si">%.2f%%</span><span class="s2"> on test data&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">K</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
<span class="n">accuracies_vae_lmnn</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
k=1, accuracy=83.60%
k=3, accuracy=82.80%
k=5, accuracy=84.80%
k=7, accuracy=84.80%
k=9, accuracy=84.00%
k=11, accuracy=84.80%
k=5 achieved highest accuracy of 84.80% on test data
</pre></div></div>
</div>
</div>
<div class="section" id="8.-W2-KNN-with-VAE-GML">
<h3>8. W2 KNN with VAE GML<a class="headerlink" href="#8.-W2-KNN-with-VAE-GML" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [68]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">accuracies_vae_gml</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">errors_vae_gml</span> <span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K</span><span class="p">:</span>
    <span class="c1"># build a model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="n">mml</span><span class="o">.</span><span class="n">wasserstein</span><span class="o">.</span><span class="n">distance</span><span class="p">,</span>\
                                                 <span class="n">metric_params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;ground metric&quot;</span><span class="p">:</span><span class="n">M_gml_vae</span><span class="p">})</span>

    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_vae_normalized</span><span class="p">,</span><span class="n">Y_train_vae</span><span class="p">)</span>

    <span class="c1"># evaluate and print accuracies and xEntropy Softmax error (for multiclass predictions)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_vae_normalized</span><span class="p">,</span> <span class="n">Y_test_vae</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_vae_normalized</span><span class="p">)</span>
    <span class="c1">#error = getXEntropySoftmaxError(prediction, Y_test)</span>
    <span class="n">error</span><span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">Y_test_vae</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2">, accuracy=</span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">score</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
    <span class="n">accuracies_vae_gml</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="n">errors_vae_gml</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

<span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">accuracies_vae_gml</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2"> achieved highest accuracy of </span><span class="si">%.2f%%</span><span class="s2"> on test data&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">K</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
<span class="n">accuracies_vae_gml</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
k=1, accuracy=81.60%
k=3, accuracy=79.20%
k=5, accuracy=81.60%
k=7, accuracy=80.00%
k=9, accuracy=80.40%
k=11, accuracy=79.60%
k=1 achieved highest accuracy of 81.60% on test data
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [86]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Plot the accuracies in the same space</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-darkgrid&#39;</span><span class="p">)</span>

<span class="c1"># create a color palette</span>
<span class="n">palette</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">&#39;Set1&#39;</span><span class="p">)</span>

<span class="c1"># Plot the accuracies in the same space</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;MNIST KNN Accuracies - LMNN and GML-Wasserstein&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;k parameter in k-nn&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Classification Accuracy&quot;</span><span class="p">)</span>
<span class="c1"># 1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">accuracies_lmnn</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;LMNN L2 SIFT&quot;</span><span class="p">)</span>
<span class="c1"># 2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">acc_wasserstein_l2</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Wasserstein GML SIFT&quot;</span><span class="p">)</span>

<span class="c1"># 3</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">acc_pca_lmnn</span><span class="p">,</span><span class="n">marker</span> <span class="o">=</span><span class="s1">&#39;+&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;LMNN L2 PCA&quot;</span><span class="p">)</span>
<span class="c1"># 4</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">acc_knn_pca_wasserstein</span><span class="p">,</span><span class="n">marker</span> <span class="o">=</span><span class="s1">&#39;+&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Wasserstein GML PCA&quot;</span><span class="p">)</span>

<span class="c1"># 5</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">accuracies_vae_lmnn</span><span class="p">,</span><span class="n">marker</span> <span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;LMNN L2 VAE&quot;</span><span class="p">)</span>
<span class="c1"># 6</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">accuracies_vae_gml</span><span class="p">,</span><span class="n">marker</span> <span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Wasserstein GML VAE&quot;</span><span class="p">)</span>


<span class="n">_</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;KNN_GML_Accuracies.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_74_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_74_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [87]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Plot the accuracies in the same space</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-darkgrid&#39;</span><span class="p">)</span>

<span class="c1"># create a color palette</span>
<span class="n">palette</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">&#39;Set1&#39;</span><span class="p">)</span>

<span class="c1"># Plot the accuracies in the same space</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;MNIST KNN Errors - LMNN and GML-Wasserstein&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;k parameter in k-nn&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Error rate using log_loss&quot;</span><span class="p">)</span>


<span class="c1"># 1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">errors_lmnn</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;LMNN L2 SIFT&quot;</span><span class="p">)</span>
<span class="c1"># 2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">errors_wasserstein_l2</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Wasserstein GML SIFT&quot;</span><span class="p">)</span>

<span class="c1"># 3</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">errors_pca_lmnn</span><span class="p">,</span><span class="n">marker</span> <span class="o">=</span><span class="s1">&#39;+&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;LMNN L2 PCA&quot;</span><span class="p">)</span>
<span class="c1"># 4</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">errors_knn_pca_wasserstein</span><span class="p">,</span><span class="n">marker</span> <span class="o">=</span><span class="s1">&#39;+&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Wasserstein GML PCA&quot;</span><span class="p">)</span>

<span class="c1"># 3</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">errors_vae_lmnn</span><span class="p">,</span><span class="n">marker</span> <span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;LMNN L2 VAE&quot;</span><span class="p">)</span>
<span class="c1"># 4</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">errors_vae_gml</span><span class="p">,</span><span class="n">marker</span> <span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Wasserstein GML VAE&quot;</span><span class="p">)</span>


<span class="n">_</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;KNN_GML_Errors.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_75_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_75_0.png" />
</div>
</div>
</div>
<div class="section" id="5.-Learn-LMNN-with-pullback-initializer-then-L2-KNN">
<h3>5. Learn LMNN with pullback initializer then L2 KNN<a class="headerlink" href="#5.-Learn-LMNN-with-pullback-initializer-then-L2-KNN" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">*</span> <span class="n">Achieves</span> <span class="n">highest</span> <span class="n">accuracy</span> <span class="n">out</span> <span class="n">of</span> <span class="nb">all</span> <span class="n">of</span> <span class="n">them</span><span class="p">,</span> <span class="n">which</span> <span class="ow">is</span> <span class="n">nice</span> <span class="n">I</span> <span class="n">guess</span>
</pre></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Learn with 1000 iterations using the pullback as initializer</span>
<span class="n">X_train_lmnn_pullback</span><span class="p">,</span> <span class="n">X_test_lmnn_pullback</span><span class="p">,</span> <span class="n">lmnn_pullback</span> <span class="o">=</span> <span class="n">train_lmnn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">Y_train</span><span class="p">,</span>
                                                                  <span class="n">pullback</span><span class="p">,</span><span class="n">steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Use the early stopping pullback i.e. LMNN on PCA is stopped early</span>
<span class="n">X_train_lmnn_pullback_2</span><span class="p">,</span> <span class="n">X_test_lmnn_pullback_2</span><span class="p">,</span> <span class="n">lmnn_pullback_2</span> <span class="o">=</span> <span class="n">train_lmnn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span>
                                                                              <span class="n">Y_train</span><span class="p">,</span><span class="n">pullback_2</span><span class="p">)</span>
<span class="n">X_train_lmnn_pullback_3</span><span class="p">,</span> <span class="n">X_test_lmnn_pullback_3</span><span class="p">,</span> <span class="n">lmnn_pullback_3</span> <span class="o">=</span> <span class="n">train_lmnn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span>
                                                                              <span class="n">Y_train</span><span class="p">,</span><span class="n">pullback_3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">accuracies_lmnn_pullback</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">errors_lmnn_pullback</span> <span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K</span><span class="p">:</span>
    <span class="c1"># build a model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_lmnn_pullback</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>

    <span class="c1"># evaluate and print accuracies and xEntropy Softmax error (for multiclass predictions)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_lmnn_pullback</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_lmnn_pullback</span><span class="p">)</span>
    <span class="c1">#error = getXEntropySoftmaxError(prediction, Y_test)</span>
    <span class="n">error</span><span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2">, accuracy=</span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">score</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
    <span class="n">accuracies_lmnn_pullback</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="n">errors_lmnn_pullback</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

<span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">accuracies_lmnn_pullback</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2"> achieved highest accuracy of </span><span class="si">%.2f%%</span><span class="s2"> on test data&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">K</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
<span class="n">accuracies_lmnn_pullback</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
k=1, accuracy=99.44%
k=3, accuracy=99.44%
k=5, accuracy=99.17%
k=7, accuracy=99.17%
k=9, accuracy=98.89%
k=11, accuracy=98.61%
k=1 achieved highest accuracy of 99.44% on test data
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [39]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">accuracies_lmnn_pullback_2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">errors_lmnn_pullback_2</span> <span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K</span><span class="p">:</span>
    <span class="c1"># build a model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_lmnn_pullback_2</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>

    <span class="c1"># evaluate and print accuracies and xEntropy Softmax error (for multiclass predictions)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_lmnn_pullback_2</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_lmnn_pullback_2</span><span class="p">)</span>
    <span class="c1">#error = getXEntropySoftmaxError(prediction, Y_test)</span>
    <span class="n">error</span><span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2">, accuracy=</span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">score</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
    <span class="n">accuracies_lmnn_pullback_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="n">errors_lmnn_pullback_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

<span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">accuracies_lmnn_pullback_2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2"> achieved highest accuracy of </span><span class="si">%.2f%%</span><span class="s2"> on test data&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">K</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
<span class="n">accuracies_lmnn_pullback_2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
k=1, accuracy=99.44%
k=3, accuracy=99.44%
k=5, accuracy=99.17%
k=7, accuracy=99.17%
k=9, accuracy=98.89%
k=11, accuracy=98.61%
k=1 achieved highest accuracy of 99.44% on test data
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [40]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">accuracies_lmnn_pullback_3</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">errors_lmnn_pullback_3</span> <span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K</span><span class="p">:</span>
    <span class="c1"># build a model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_lmnn_pullback_3</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>

    <span class="c1"># evaluate and print accuracies and xEntropy Softmax error (for multiclass predictions)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_lmnn_pullback_3</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_lmnn_pullback_3</span><span class="p">)</span>
    <span class="c1">#error = getXEntropySoftmaxError(prediction, Y_test)</span>
    <span class="n">error</span><span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2">, accuracy=</span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">score</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
    <span class="n">accuracies_lmnn_pullback_3</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="n">errors_lmnn_pullback_3</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

<span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">accuracies_lmnn_pullback_3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2"> achieved highest accuracy of </span><span class="si">%.2f%%</span><span class="s2"> on test data&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">K</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
<span class="n">accuracies_lmnn_pullback_3</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
k=1, accuracy=99.17%
k=3, accuracy=98.89%
k=5, accuracy=98.89%
k=7, accuracy=98.61%
k=9, accuracy=98.61%
k=11, accuracy=98.61%
k=1 achieved highest accuracy of 99.17% on test data
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [41]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># LMNN after using the pullback metric as the initializer</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>

<span class="n">L_pullback</span> <span class="o">=</span> <span class="n">lmnn_pullback</span><span class="o">.</span><span class="n">get_linear_transform</span><span class="p">()</span>
<span class="n">M_pullback_upper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_pullback</span><span class="p">,</span> <span class="n">L_pullback</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">M_pullback_upper</span><span class="p">);</span>

<span class="n">L_pullback_2</span> <span class="o">=</span> <span class="n">lmnn_pullback_2</span><span class="o">.</span><span class="n">get_linear_transform</span><span class="p">()</span>
<span class="n">M_pullback_upper_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_pullback_2</span><span class="p">,</span> <span class="n">L_pullback_2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">M_pullback_upper_2</span><span class="p">);</span>

<span class="n">L_pullback_3</span> <span class="o">=</span> <span class="n">lmnn_pullback_3</span><span class="o">.</span><span class="n">get_linear_transform</span><span class="p">()</span>
<span class="n">M_pullback_upper_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_pullback_3</span><span class="p">,</span> <span class="n">L_pullback_3</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">M_pullback_upper_3</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_82_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_82_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [42]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Observe how 1000 iterations and 500 iterations are super close.</span>
<span class="c1"># 100 iterations is almost not visible</span>
<span class="n">diff</span> <span class="o">=</span>  <span class="n">L_upper</span> <span class="o">-</span> <span class="n">L_pullback</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">diff</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
6.78556589744
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [222]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">hist_zero</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">9</span><span class="p">])</span>
<span class="n">hist_four</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">9</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;zero&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [244]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">norm_hist</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Pixel Intensity&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Count&quot;</span><span class="p">);</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;four_hist&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_86_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_86_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [246]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">9</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">norm_hist</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Pixel Intensity&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Count&quot;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">1.4</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;zero_hist&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_87_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_87_0.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [216]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">bins_hist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="c1"># By default metric =&#39;sqeuclidean&#39; in the function</span>
<span class="n">M_hist</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">bins_hist</span><span class="p">,</span><span class="n">bins_hist</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [233]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>

<span></span><span class="n">hist_zero_normalized</span> <span class="o">=</span> <span class="n">hist_zero</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">hist_zero</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">hist_four_normalized</span> <span class="o">=</span> <span class="n">hist_four</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">hist_four</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [234]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="p">[</span><span class="n">wc</span><span class="p">,</span><span class="n">m</span><span class="p">]</span> <span class="o">=</span> <span class="n">mml</span><span class="o">.</span><span class="n">wasserstein</span><span class="o">.</span><span class="n">coupling</span><span class="p">(</span><span class="n">hist_zero_normalized</span><span class="p">,</span>
                              <span class="n">hist_four_normalized</span><span class="p">,</span>
                              <span class="o">**</span><span class="p">{</span><span class="s2">&quot;ground metric&quot;</span><span class="p">:</span><span class="n">M_hist</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="p">[</span><span class="n">wc</span><span class="p">,</span><span class="n">m</span><span class="p">]</span> <span class="o">=</span> <span class="n">mml</span><span class="o">.</span><span class="n">wasserstein</span><span class="o">.</span><span class="n">coupling</span><span class="p">(</span><span class="n">X_train_normalized</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span>
                              <span class="n">X_train_normalized</span><span class="p">[</span><span class="mi">9</span><span class="p">],</span>
                              <span class="o">**</span><span class="p">{</span><span class="s2">&quot;ground metric&quot;</span><span class="p">:</span><span class="n">M_original</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [242]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">wc</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Pixel amounts in 0 morphed into 4&quot;</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;Wasserstein_coupling&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_92_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_92_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [243]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">pylab</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">M_hist</span><span class="p">,</span><span class="n">xticklabels</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="n">yticklabels</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Euclidean Ground Metric&quot;</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;Euclidean_Metric&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_93_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_93_0.png" />
</div>
</div>
<div class="section" id="Ground-ification-of-the-metric">
<h4>Ground-ification of the metric<a class="headerlink" href="#Ground-ification-of-the-metric" title="Permalink to this headline">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [66]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#d_pullback_euclidean1 = np.zeros((36,36))</span>
<span class="n">d_pullback_euclidean2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">25</span><span class="p">,</span><span class="mi">25</span><span class="p">))</span>
<span class="c1">#e = np.eye(64)</span>

<span class="c1"># Pullback euclidean metric through given L ...</span>
<span class="c1"># def pullback(L_original):</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">25</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">25</span><span class="p">):</span>
        <span class="c1">#d_pullback_euclidean1[i][j] = np.linalg.norm(M_gml_pca[i] -  M_gml_pca[j])</span>
        <span class="n">d_pullback_euclidean2</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">M_gml_vae</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">M_gml_vae</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [64]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">M_gml_pca</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[64]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>&lt;matplotlib.image.AxesImage at 0x12556a438&gt;
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_96_1.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_96_1.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [103]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">d_pullback_euclidean1</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Euclidean pullback of LMNN L&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">d_pullback_euclidean2</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Euclidean pullback of LMNN M&quot;</span><span class="p">);</span>

<span class="c1">#phi_x = np.dot(d_patric,x1)</span>
<span class="c1">#M_LMNN = ot.dist(phi_x,phi_x,metric=&#39;euclidean&#39;)</span>
<span class="c1">#M_LMNN.shape</span>
<span class="c1">#plt.imshow(M_LMNN)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_97_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_97_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="6.-LMNN-using-L2-pullback-as-initializer-then-W2-KNN">
<h3>6. LMNN using L2 pullback as initializer then W2-KNN<a class="headerlink" href="#6.-LMNN-using-L2-pullback-as-initializer-then-W2-KNN" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>* Only $W_2$ for now
* Does it make sense?
* takes ages..get 99 %
</pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [104]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">K1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>
<span class="n">errors_pullback_wasserstein</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">acc_pullback_wasserstein</span> <span class="o">=</span> <span class="p">[]</span>


<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K1</span><span class="p">:</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="n">mml</span><span class="o">.</span><span class="n">wasserstein</span><span class="o">.</span><span class="n">distance</span><span class="p">,</span>\
                                                  <span class="n">metric_params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;ground metric&quot;</span><span class="p">:</span><span class="n">d_pullback_euclidean1</span><span class="p">})</span>
    <span class="n">m</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_normalized</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>

    <span class="n">score</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_normalized</span><span class="p">,</span><span class="n">Y_test</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_normalized</span><span class="p">)</span>

    <span class="c1">#error = getXEntropySoftmaxError(prediction_proba, Y_test)</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2">, accuracy=</span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">score</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
    <span class="n">acc_pullback_wasserstein</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="n">errors_pullback_wasserstein</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

<span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">acc_pullback_wasserstein</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k=</span><span class="si">%d</span><span class="s2"> achieved highest accuracy of </span><span class="si">%.2f%%</span><span class="s2"> on test data&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">K</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
<span class="n">acc_pullback_wasserstein</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
k=1, accuracy=99.17%
k=3, accuracy=97.78%
k=1 achieved highest accuracy of 99.17% on test data
</pre></div></div>
</div>
<div class="section" id="Accuracies-and-errors">
<h4>Accuracies and errors<a class="headerlink" href="#Accuracies-and-errors" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>TODO: add AUC-ROC</li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [110]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Plot the errors in the same space</span>
<span class="c1"># Interestingly, the pullback LMNN does the best out of all of them</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Errors for different metrics&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;k parameter in k-nn&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Error rate using log_loss&quot;</span><span class="p">)</span>
<span class="c1"># 1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">errors_lmnn</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;+&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;LMNN L2&quot;</span><span class="p">)</span>
<span class="c1"># 2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">errors_wasserstein_l2</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Wasserstein L2&quot;</span><span class="p">)</span>
<span class="c1"># 3</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">errors_pca_lmnn</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;PCA LMNN L2&quot;</span><span class="p">)</span>
<span class="c1"># 4</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">errors_knn_pca_wasserstein</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;PCA LMNN Wasserstein&quot;</span><span class="p">)</span>
<span class="c1"># 5</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">errors_lmnn_pullback</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Pullback LMNN L2&quot;</span><span class="p">)</span>

<span class="n">_</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_101_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_101_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="PCA">
<h3>PCA<a class="headerlink" href="#PCA" title="Permalink to this headline">¶</a></h3>
<p><strong>Important question: Do we really need to standardize? I should try
both approaches</strong></p>
<ul class="simple">
<li>Use PCA to learn a (linear) embedding of the original space.</li>
<li>Compute LMNN on the reduced space and do KNN with L_2 and W_2</li>
<li>Do a pullback of the metric learned (GML- Cuturi) from reduced space
to original space</li>
<li>Use the pullback as an initializer for LMNN and GML on the original
space Also</li>
<li>Think about Lebanon and Riemannian metric learning</li>
</ul>
<p><strong>Miscelaneouss - previous ideas</strong>: - Step 1: do PCA on X_train. Then do
LMNN on that, then do Wasserstein on that and KNN based on G_Wasserstein
- Step 2: do Wasserstein on the initial LMNN and then KNN.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Transform the data using 95% of variance.</span>
<span class="n">std_scale</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_train_std</span> <span class="o">=</span> <span class="n">std_scale</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_std</span> <span class="o">=</span> <span class="n">std_scale</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">38</span><span class="p">)</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_std</span><span class="p">)</span>
<span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train_std</span><span class="p">)</span>
<span class="n">X_test_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_std</span><span class="p">)</span>

<span class="c1"># Sanity check for PCA - connecting the dots to LMNN</span>
<span class="c1">#P = pca.components_</span>
<span class="c1">#I = np.dot(P,P.T)</span>
<span class="c1">#plt.imshow(I)</span>
<span class="c1">#Constraint is M = I</span>
<span class="c1">#print(I.diagonal().sum())</span>
<span class="c1">#print(I.shape)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Apply LMNN to PCA data</span>
<span class="n">init_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">38</span><span class="p">,</span><span class="mi">38</span><span class="p">)</span>
<span class="p">[</span><span class="n">X_train_pca_lmnn</span><span class="p">,</span> <span class="n">X_test_pca_lmnn</span><span class="p">,</span> <span class="n">lmnn_pca</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_lmnn</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span><span class="n">X_test_pca</span><span class="p">,</span><span class="n">Y_train</span><span class="p">,</span><span class="n">init_t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="Find-LMNN-metric-using-early-stopping-and-pullback-that-one-to-bigger-space">
<h4>Find LMNN metric using early stopping and pullback that one to bigger space<a class="headerlink" href="#Find-LMNN-metric-using-early-stopping-and-pullback-that-one-to-bigger-space" title="Permalink to this headline">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Apply LMNN to PCA data</span>
<span class="n">init_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">38</span><span class="p">,</span><span class="mi">38</span><span class="p">)</span>
<span class="p">[</span><span class="n">X_train_pca_lmnn_2</span><span class="p">,</span> <span class="n">X_test_pca_lmnn_2</span><span class="p">,</span> <span class="n">lmnn_pca_2</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_lmnn</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span><span class="n">X_test_pca</span><span class="p">,</span>
                                                                 <span class="n">Y_train</span><span class="p">,</span><span class="n">init_t</span><span class="p">,</span><span class="n">steps</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="p">[</span><span class="n">X_train_pca_lmnn_3</span><span class="p">,</span> <span class="n">X_test_pca_lmnn_3</span><span class="p">,</span> <span class="n">lmnn_pca_3</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_lmnn</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span><span class="n">X_test_pca</span><span class="p">,</span>
                                                                 <span class="n">Y_train</span><span class="p">,</span><span class="n">init_t</span><span class="p">,</span><span class="n">steps</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Plot-and-calculate-the-LMNN-metric-on-the-PCA-space">
<h4>Plot and calculate the LMNN metric on the PCA space<a class="headerlink" href="#Plot-and-calculate-the-LMNN-metric-on-the-PCA-space" title="Permalink to this headline">¶</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># LMNN Upper metric</span>
<span class="n">L_upper</span> <span class="o">=</span> <span class="n">lmnn</span><span class="o">.</span><span class="n">get_linear_transform</span><span class="p">()</span>
<span class="n">M_upper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_upper</span><span class="p">,</span><span class="n">L_upper</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="c1"># PCA LMNN metric</span>
<span class="n">L_pca</span> <span class="o">=</span> <span class="n">lmnn_pca</span><span class="o">.</span><span class="n">get_linear_transform</span><span class="p">()</span>
<span class="n">M_pca</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_pca</span><span class="p">,</span><span class="n">L_pca</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="c1"># PCA LMNN metric 2 and 3</span>
<span class="n">L_pca_2</span> <span class="o">=</span> <span class="n">lmnn_pca_2</span><span class="o">.</span><span class="n">get_linear_transform</span><span class="p">()</span>
<span class="n">L_pca_3</span> <span class="o">=</span> <span class="n">lmnn_pca_3</span><span class="o">.</span><span class="n">get_linear_transform</span><span class="p">()</span>

<span class="n">M_pca_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_pca_2</span><span class="p">,</span><span class="n">L_pca_2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">M_pca_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_pca_3</span><span class="p">,</span><span class="n">L_pca_3</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">M_upper</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Original LMNN metric&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">M_pca</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;PCA LMNN metric 1000 iter&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">M_pca_2</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;PCA LMNN metric 500 iter&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">M_pca_3</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;PCA LMNN metric 100 iter&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_109_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_109_0.png" />
</div>
</div>
<p>Pullback of PCA metric through the inverse transformation to reach the
dimension of the upper metric</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">P</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">components_</span>

<span class="c1"># Use pullback for now</span>
<span class="n">pullback</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_pca</span><span class="p">,</span><span class="n">P</span><span class="p">))</span>
<span class="n">pullback_metric</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M_pca</span><span class="p">,</span><span class="n">P</span><span class="p">))</span>

<span class="n">pullback_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_pca_2</span><span class="p">,</span><span class="n">P</span><span class="p">))</span>
<span class="n">pullback_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_pca_3</span><span class="p">,</span><span class="n">P</span><span class="p">))</span>

<span class="c1">#eigenvector_matrix.T * metric_pca * eigenvector_matrix</span>

<span class="c1"># VINCENT</span>
<span class="c1">#pb(x1,x2) = lmnn_pca(f(x1),f(x2))</span>
<span class="c1"># Formula1 weinberger</span>
<span class="c1">#pb(x1,x2) = (L_pca * (P*x1 - P*x2))**2</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">pullback</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Pullback L&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">pullback_metric</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Pullback M ~ L squared&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_112_0.png" src="../_images/.ipynb_checkpoints_Multiscale_Metric_Learning-GPU-checkpoint_112_0.png" />
</div>
</div>
<p>Below is not complete</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">mml</span><span class="o">.</span><span class="n">ot_testing</span><span class="o">.</span><span class="n">is_metric</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">pullback_metric</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[34]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>True
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Miscellaneous">
<h3>Miscellaneous<a class="headerlink" href="#Miscellaneous" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [271]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Below is for data reconstruction, we don&#39;t really need that.</span>
<span class="n">rows</span> <span class="o">=</span> <span class="n">X_train_pca_lmnn</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">col</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">reconstructed_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">rows</span><span class="p">,</span><span class="n">col</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rows</span><span class="p">):</span>
    <span class="n">reconstructed_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">mean_</span> <span class="o">+</span> <span class="n">X_train_pca_lmnn</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [272]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">rows_test</span> <span class="o">=</span> <span class="n">X_test_pca_lmnn</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">col_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">reconstructed_test_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">rows_test</span><span class="p">,</span><span class="n">col_test</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rows_test</span><span class="p">):</span>
    <span class="n">reconstructed_test_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">mean_</span> <span class="o">+</span> <span class="n">X_test_pca_lmnn</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<hr class="docutils" />
<p><strong>Below is educational purposes, courtesy of IAML and not important</strong></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Standardize the data and apply PCA on Hellinger representation of the digits</span>
<span class="n">std_scale</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_train_std</span> <span class="o">=</span> <span class="n">std_scale</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_std</span> <span class="o">=</span> <span class="n">std_scale</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">X_train_std</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_std</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="o">.</span><span class="n">size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;n_components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;explained_variance_ratio_&#39;</span><span class="p">)</span>
<span class="n">n_eigenvectors_95pc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span> <span class="o">&gt;</span> <span class="o">.</span><span class="mi">95</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">max_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">n_eigenvectors_95pc</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="n">max_variance</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;95% variance explained</span><span class="se">\n</span><span class="s1">by </span><span class="si">{}</span><span class="s1"> eigenvectors&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_eigenvectors_95pc</span><span class="p">),</span>
             <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">n_eigenvectors_95pc</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">[</span><span class="n">n_eigenvectors_95pc</span><span class="p">]),</span>
             <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="n">n_eigenvectors_95pc</span><span class="o">+</span><span class="mi">10</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">[</span><span class="n">n_eigenvectors_95pc</span><span class="p">]</span><span class="o">+.</span><span class="mi">05</span><span class="p">),</span>
             <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">shrink</span><span class="o">=</span><span class="mf">0.05</span><span class="p">),)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">margins</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">tight</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idx</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>

<span class="c1"># Can change from X_train_std to X_train if you don&#39;t want the scaled version</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X_train_std</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)),</span> <span class="n">square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;0.1f&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Scaled original img&#39;</span><span class="p">)</span>

<span class="c1"># Only transform one digit and use different number of eigenvectors to reconstruct.</span>
<span class="n">img_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train_std</span><span class="p">[</span><span class="n">idx</span><span class="p">,:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">pca_coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
<span class="n">pc_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">29</span><span class="p">,</span><span class="mi">38</span><span class="p">,</span><span class="mi">64</span><span class="p">]</span>
<span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">nr_pcs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pc_list</span><span class="p">):</span>
    <span class="n">ii</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># Choose number of eigen-components to reconstruct.</span>
    <span class="n">pca_coefs</span><span class="p">[:</span><span class="n">nr_pcs</span><span class="p">]</span> <span class="o">=</span> <span class="n">img_pca</span><span class="p">[:</span><span class="n">nr_pcs</span><span class="p">]</span>
    <span class="n">img</span> <span class="o">=</span> <span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">mean_</span> <span class="o">+</span> <span class="n">pca_coefs</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>

    <span class="c1"># Display the other reconstructions</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;0.1f&#39;</span><span class="p">)</span>
    <span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">img_pca</span><span class="p">[:</span><span class="n">nr_pcs</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">explained_var</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">[:</span><span class="n">nr_pcs</span><span class="p">]),</span> <span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Reconstruction with </span><span class="si">{}</span><span class="s1"> PCs</span><span class="se">\n</span><span class="si">{}</span><span class="s1">% variance explained&#39;</span><span class="o">.</span>\
                     <span class="nb">format</span><span class="p">(</span><span class="n">nr_pcs</span><span class="p">,</span> <span class="n">explained_var</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Mahalanobis is a valid metric - but it&#39;s not zero on the diagonal!! on the contrary!</span>
<span class="n">mahalanobis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">l_transform</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">l_transform</span><span class="p">)</span>
<span class="n">test_is_metric</span><span class="p">(</span><span class="n">mahalanobis</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">metric_learn</span> <span class="k">import</span> <span class="n">Covariance</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_iris</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>

<span class="n">cov</span> <span class="o">=</span> <span class="n">Covariance</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="p">)</span>
<span class="n">dummy_X</span> <span class="o">=</span> <span class="n">cov</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">iris</span><span class="p">)</span>

<span class="c1">#plt.imshow(digits.images[1]);</span>
<span class="c1">#x_1 = X_test_lmnn[1].reshape(8,8)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]));</span>

<span class="c1"># how many 0s do we have? plenty</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">getXEntropySoftmaxError</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span><span class="n">targets</span><span class="p">):</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">/=</span> <span class="n">probs</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">targets</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Patric Fulop.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'58876c6',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: ''
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>